<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elastics on</title><link>https://koktlzz.github.io/elastic/</link><description>Recent content in Elastics on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Wed, 04 Nov 2020 09:19:42 +0100</lastBuildDate><atom:link href="https://koktlzz.github.io/elastic/index.xml" rel="self" type="application/rss+xml"/><item><title>Get Started</title><link>https://koktlzz.github.io/elastic/elasticstack/intro/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticstack/intro/</guid><description>官方网站 https://www.elastic.co/cn/
推荐阅读 官方文档
ELKstack 中文指南</description></item><item><title>单节点部署流程</title><link>https://koktlzz.github.io/elastic/elasticstack/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticstack/%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B/</guid><description>部署 Elastic Search 下载安装包 下载地址： https://www.elastic.co/cn/downloads/elasticsearch
解压 tar -xzf tar -xzf elasticsearch-7.10.1-linux-x86_64.tar.gz 添加用户 root 用户默认无法启动 Elastic Search，因此需要添加一个普通用户并修改文件夹的拥有者：
useradd elasticsearch chown -R elasticsearch:elasticsearch elasticsearch-7.10.1 su elasticsearch 启动应用 cd elasticsearch-7.10.1 ./bin/elasticsearch 检查应用 访问本机的 9200 端口后返回：
[elasticsearch@GWR1 elasticsearch-7.10.1]$ curl localhost:9200 { &amp;#34;name&amp;#34; : &amp;#34;GWR1&amp;#34;, &amp;#34;cluster_name&amp;#34; : &amp;#34;elasticsearch&amp;#34;, &amp;#34;cluster_uuid&amp;#34; : &amp;#34;0zZo-UItRjmbKkfHwqObnw&amp;#34;, &amp;#34;version&amp;#34; : { &amp;#34;number&amp;#34; : &amp;#34;7.10.1&amp;#34;, &amp;#34;build_flavor&amp;#34; : &amp;#34;default&amp;#34;, &amp;#34;build_type&amp;#34; : &amp;#34;tar&amp;#34;, &amp;#34;build_hash&amp;#34; : &amp;#34;1c34507e66d7db1211f66f3513706fdf548736aa&amp;#34;, &amp;#34;build_date&amp;#34; : &amp;#34;2020-12-05T01:00:33.671820Z&amp;#34;, &amp;#34;build_snapshot&amp;#34; : false, &amp;#34;lucene_version&amp;#34; : &amp;#34;8.</description></item><item><title>Infrastructure</title><link>https://koktlzz.github.io/elastic/elasticsearch/infrastructure/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/infrastructure/</guid><description>基本概念与 MySQL 的对比 ElasticSearch MySQL Index Database Type （未来将删除） Table Document Row Field Column Mapping Schema Everything is indexed Index Query DSL SQL GET HTTP SELECT PUT HTTP UPDATE 倒排索引 为了实现倒排索引，Elasticsearch 中的每个文档（document）中不仅保存了其自身数据，还包括了以下内容：
_id 字段：每个文档在索引中的唯一标识； 词频 TF：每个 token 在文档中出现的次数，用于相关性评分； 位置 Position：token 在文档中分词的位置，用于 match_phrase 类型的查询； 偏移量 Offset：记录 token 开始和结束的位置，实现高亮显示。 创建倒排索引 对文档内容进行分词，形成一个个 token（可以理解为单词），保存 token 和文档_id 之间的映射关系。详见 Text Analysis。</description></item><item><title>Mapping</title><link>https://koktlzz.github.io/elastic/elasticsearch/mapping/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/mapping/</guid><description>概述 Mapping 定义了文档（document）及其包含的字段（filed）在存储和被索引时的过程和方式。 每个文档都是一组字段的集合，而每个字段也有自己的数据类型。Mapping 中不仅包含了与文档相关的字段列表，还包括元数据字段（例如_source），因此可以自定义文档相关元数据的处理方式。 Mapping 有 Dynamic（动态生成）和 Explicit（显式指定）两种实现方式，可根据字段的特点配合使用。 Dynamic Mapping 我们只需创建一条文档并指定其所在索引，Dynamic Mapping 便会为我们自动生成索引、字段以及字段类型。
PUT /my_index/_doc/first_doc { &amp;#34;num&amp;#34;: 5, &amp;#34;text&amp;#34;: &amp;#34;5&amp;#34; } 查看该索引的 Mapping，我们发现字段值为数字的num字段的类型自动映射为 long 类型。而text字段映射为了 text 类型，其子字段text.keyword类型则为 keyword，可用于排序和聚合等操作（详见：multi-fields）。
GET /my_index/_mapping // 返回 { &amp;#34;my_index&amp;#34; : { &amp;#34;mappings&amp;#34; : { &amp;#34;properties&amp;#34; : { &amp;#34;num&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;long&amp;#34; }, &amp;#34;text&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;text&amp;#34;, &amp;#34;fields&amp;#34; : { &amp;#34;keyword&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;keyword&amp;#34;, &amp;#34;ignore_above&amp;#34; : 256 } } } } } } } 但大多数情况下，我们可能希望值为&amp;quot;123&amp;quot;和&amp;quot;2021/02/26&amp;quot;这样的字段能够分别映射为 long 和 date 类型，这时便需要对 Dynamic Mapping 的方式进行自定义。</description></item><item><title>Text analysis</title><link>https://koktlzz.github.io/elastic/elasticsearch/textanalysis/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/textanalysis/</guid><description>概述 Text analysis（分词）使 Elasticsearch 在执行全文搜索时，不仅可以精确匹配搜索项，还能够返回与其相关的所有结果。 举例来说，如果一个索引中有以下几个文档：
A quick brown fox jumps over the lazy dog fast fox foxes leap 当我们搜索Quick fox jumps，我们很可能希望搜索结果中包含了上述文档，因为它们都与搜索项有着密切的关系：包含、复数和同义词。这便是分词器存在的价值，它让 Elasticsearch 的搜索结果更加符合使用者的预期。
组成 在 Elasticsearch 中可以通过内置分词器实现分词，也可以按需定制分词器。 分词器由三部分组成：
Character Filters Character Filters 将原始文本作为字符流接受并进行处理，它的作用是整理字符串。例如将印度-阿拉伯数字 （٠‎١٢٣٤٥٦٧٨‎٩‎）转化为阿拉伯-拉丁数字（0123456789）、去除 HTML 元素、将&amp;amp;转化为 and 等。一个分词器可以有 0 个或多个 Character Filters，多个 Character Filters 的加载是有顺序的。
Tokenizer Tokenizer 将字符流按照给定的规则切分为 Token（可以看作为单词）。比如 whitespace 分词器在遇到空格和标点的时候，会将文本进行拆分。同时，Tokenizer 还会记录每个 Token 在文本中的位置（position）、占位长度（positionLength）以及首尾字符的偏移量（start_offset/end_offset）。下图中每个 Token 的 positionLength 都为 1，position 分别为 0、1 和 2：
与 Character Filters 不同的是，每个分词器有且仅有一个 Tokenizer。</description></item><item><title>Template</title><link>https://koktlzz.github.io/elastic/elasticsearch/template/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/template/</guid><description>概述 Template（模板）规定了 Elasticsearch 在创建索引时是如何对其进行配置的；
如果索引与多个索引模板匹配，则使用优先级最高的索引模板。 模板的priority（旧版本中为order) 字段定义了模板的优先级。
索引在创建时显式声明的配置优先级高于其匹配的模板中的配置。
分类 模板有两种类型：Index template（索引模板）和 Component templates（组件模板）。
组件模板是可以重用的构建组件，用于配置索引的 Mappings、Settings 和 Aliases（别名）。 组件模板还可以用来构造索引模板，但它们不会直接应用于一组索引。 索引模板既可以是一个包含组件模板的集合，也可以直接指定索引的 Mappings、Settings 和 Aliases。 应用 首先使用 Elasticsearch API 创建两个组件模板，它们分别对@timestamp和ip_address字段的 Mapping 方式进行了配置：
PUT _component_template/component_template1 { &amp;#34;template&amp;#34;: { &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;@timestamp&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;date&amp;#34; } } } } } PUT _component_template/other_component_template { &amp;#34;template&amp;#34;: { &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;ip_address&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;ip&amp;#34; } } } } } 然后我们创建一个索引模板，它是上述两个组件模板的集合，同时还对索引的分片数、别名以及host_name字段的 Mapping 方式进行了相关配置：</description></item><item><title>ILM</title><link>https://koktlzz.github.io/elastic/elasticsearch/ilm/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/ilm/</guid><description>概述 我们可以通过配置索引生命周期管理 ILM（Index Lifecycle Management）策略，来自动管理索引以达到某些效果：
Rollover：当索引达到一定大小、创建超过一定时间或文档达到一定数量时，创建一个新索引； Shrink：减少索引中主分片的数量； Force merge：手动触发合并以减少索引中每个分片中的 segment 数，并释放已删除文档所使用的空间； Freeze：将索引设为只读，最大程度地减少其内存占用量； Delete：永久删除索引，包括其所有数据和元数据。 举例来说，我们要一台 ATM 的指标数据索引到 Elasticsearch 中，那么便可以配置相关的 ILM 策略：
当索引主分片的总大小达到 50GB 时，创建新索引； 将旧索引标记为只读，并将其缩小为单个分片； 7 天后，将索引移至较便宜的硬件上； 30 天后，删除索引。 索引的生命周期 索引的生命周期共分为 4 个阶段（Phase）：
Hot：索引正在不断更新且可以被搜索到； Warm：索引不再更新但可以被搜索到； Cold：索引不再更新且很少被搜索。虽然依然可以被搜索，但是搜索速度可能会变慢； Delete：索引不再被需要，可以安全地将其删除。 当某阶段中的所有动作均完成（Phase execution）且超过了最小持续时间，ILM 便会将索引转换到下一个阶段（Phase transitions）。每个阶段默认的最小持续时间为 0，因此我们在配置 ILM 策略时，一般会为每个阶段设置一个最小持续时间。由于 Elasticsearch 只能在健康状况为绿色的集群上执行某些清理任务，所以 ILM 可能会在健康状况为黄色的集群中失效。
ILM 控制每个阶段执行动作的顺序和与每个动作相关的索引操作的步骤。
数据层 数据层（data tier）是 Elasticsearch 集群中保存相同类型索引的节点集合。此处索引的类型是根据其生命周期划分的，因此对应的数据层分别为：Hot tier，Warm tier 和 Cold tier。上述三种数据层常用来保存如日志、指标等时间序列数据，而对产品目录、用户档案等需要持久化存储的数据进行生命周期管理是没有意义的，因此 Elasticsearch 引入 Content tier 来存放这种长时间内相对恒定的数据。</description></item><item><title>Snapshot</title><link>https://koktlzz.github.io/elastic/elasticsearch/snapshot/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/snapshot/</guid><description>我们可以对整个 Elasticsearch 集群或集群中的部分索引/数据流拍摄快照，从而实现数据的备份。
快照仓库 在创建快照前，我们必须注册一个可以存放快照的仓库 snapshot repository。snapshot repository 既可以是本地仓库，也可以是云服务商通过 对象存储技术（Object-based Storage）提供的远程仓库，如 Amazon S3, HDFS, Microsoft Azure, 和 Google Cloud Storage 等。如果在多个集群中注册同一快照存储库，则应当只有一个集群具有对该仓库的读写权限，仓库对其他集群应设置为只读。
我们可以通过 Snapshot and restore APIs 创建、查看或删除快照仓库，也可以在 Elastic Cloud 的管理界面直接手动操作。
快照生命周期管理 当我们创建了一个快照仓库后，便可以通过 Snapshot and restore APIs 手动为集群中的索引或数据流创建快照了。但在实际应用中，我们往往需要 Elasticsearch 能够每隔一段时间便自动拍摄快照，这便是快照生命周期管理 SLM（Snapshot Lifecycle Management）策略的作用。
PUT /_slm/policy/nightly-snapshots { &amp;#34;schedule&amp;#34;: &amp;#34;0 30 1 * * ?&amp;#34;, // 每天的 1:30 分拍摄快照（UTC 时间） &amp;#34;name&amp;#34;: &amp;#34;&amp;lt;nightly-snap-{now/d}&amp;gt;&amp;#34;, // 快照名称以 nightly-snap-开头，以拍摄日期结尾 &amp;#34;repository&amp;#34;: &amp;#34;my_repository&amp;#34;, // 快照存放于名为 my_repository 的快照仓库中 &amp;#34;config&amp;#34;: { &amp;#34;indices&amp;#34;: [&amp;#34;*&amp;#34;] // 对所有索引/数据流拍摄快照 }, &amp;#34;retention&amp;#34;: { // 快照的保留策略与上方快照创建任务的执行无关，但仅对 SLM 创建的快照有效，不会作用于手动创建的快照上 &amp;#34;expire_after&amp;#34;: &amp;#34;30d&amp;#34;, // 每个快照保留 30 天 &amp;#34;min_count&amp;#34;: 5, // 快照最少保留 5 个（若不足 5 个，则即使超过 30 天也不会删除） &amp;#34;max_count&amp;#34;: 50 // 快照最多保留 50 个（若超过 50 个，则即使不足 30 天也会删除） } } 在 Elastic Cloud 创建 SLM 策略则更加方便：</description></item><item><title>性能调优</title><link>https://koktlzz.github.io/elastic/elasticsearch/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/elasticsearch/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</guid><description>吞吐量（throughput）和延迟（latency）是评估 Elasticsearch 集群性能的指标，前者代表每秒写入（index）或查询（search）文档的数量，后者则代表单个请求的延迟。上述指标之间也有一定联系：延迟越低，吞吐量就越高。
JVM 内存压力 Elasticsearch 集群的吞吐量显然与节点的负载相关，尤其是大量的请求将引起节点的 JVM 内存压力升高。Elasticsearch 使用断路器（Circuit Breaker）来防止节点出现 JVM 堆内存溢出。如果 Elasticsearch 评估一项操作将触发断路器，那么便会返回一个 HTTP 错误码 429：
{ &amp;#39;error&amp;#39;: { &amp;#39;type&amp;#39;: &amp;#39;circuit_breaking_exception&amp;#39;, &amp;#39;reason&amp;#39;: &amp;#39;[parent] Data too large, data for [&amp;lt;http_request&amp;gt;] would be [123848638/118.1mb], which is larger than the limit of [123273216/117.5mb], real usage: [120182112/114.6mb], new bytes reserved: [3666526/3.4mb]&amp;#39;, &amp;#39;bytes_wanted&amp;#39;: 123848638, &amp;#39;bytes_limit&amp;#39;: 123273216, &amp;#39;durability&amp;#39;: &amp;#39;TRANSIENT&amp;#39; }, &amp;#39;status&amp;#39;: 429 } 由于断路器有多个，首先应先查看其具体的触发情况：
GET _nodes/stats/breaker // 返回 &amp;#34;breakers&amp;#34; : { &amp;#34;request&amp;#34; : { &amp;#34;limit_size_in_bytes&amp;#34; : 1278030643, &amp;#34;limit_size&amp;#34; : &amp;#34;1.</description></item><item><title>Intro</title><link>https://koktlzz.github.io/elastic/kafka/intro/</link><pubDate>Wed, 04 Nov 2020 09:19:42 +0100</pubDate><guid>https://koktlzz.github.io/elastic/kafka/intro/</guid><description>架构 概念 Broker：Kafka 集群中的一台或多台服务器； Topic：逻辑概念。根据消息的类型，将其分为各种主题（Topic），以此区分不同的业务数据； Partition：物理概念。每个 Topic 可分为多个分区（Partition），而每个 Partition 都是有序且顺序不变的消息队列； Offset：每条消息都会被分配一个连续的、在其 Partition 内唯一的标识来记录顺序，即偏移量（Offset）； Replica：可以为每个 Partition 创建副本（Replica）来实现高可用； Leader/Follwer：一个 Leader 副本处理读写请求，多个 Follower 副本同步数据。每台 Broker 上都维护着某些 Partition 的 Leader 副本和某些 Partition 的 Follower 副本，因此集群的负载是均衡的； Producer：消息的生产者，将数据主动发送到指定的 Topic； Consumer：消息的消费者，从订阅的 Topic 中主动拉取数据； Consumer Group：将多个 Consumer 划分为组，组内的 Consumer 可以并行地消费 Topic 中的数据； Zookeeper：Kafka 集群中的一个 Broker 会被选举为 Controller，负责管理集群中其他 Broker 的上下线、Partition 副本的分配和 ISR 成员变化、Leader 的选举等工作。而 Controller 的管理工作依赖于 Zookeeper，Broker 必须能通过 Zookeeper 的心跳机制维持其与 Zookeeper 的会话。 基本配置 [root@test-ece-kafka2 kafka_2.11-1.1.1]# ls config/ connect-console-sink.</description></item></channel></rss>